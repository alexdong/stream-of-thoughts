<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Dwarkesh’s Fossil Fuel Analogy | Alex Dong’s Blog</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Dwarkesh’s Fossil Fuel Analogy" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Dwarkesh published a short follow-up to his previous interview with Richard Sutton that I commented extensively last week." />
<meta property="og:description" content="Dwarkesh published a short follow-up to his previous interview with Richard Sutton that I commented extensively last week." />
<link rel="canonical" href="https://alexdong.com/dwarkesh-s-fossil-fuel-analogy.html" />
<meta property="og:url" content="https://alexdong.com/dwarkesh-s-fossil-fuel-analogy.html" />
<meta property="og:site_name" content="Alex Dong’s Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-10-06T22:35:00+13:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Dwarkesh’s Fossil Fuel Analogy" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-10-06T22:35:00+13:00","datePublished":"2025-10-06T22:35:00+13:00","description":"Dwarkesh published a short follow-up to his previous interview with Richard Sutton that I commented extensively last week.","headline":"Dwarkesh’s Fossil Fuel Analogy","mainEntityOfPage":{"@type":"WebPage","@id":"https://alexdong.com/dwarkesh-s-fossil-fuel-analogy.html"},"url":"https://alexdong.com/dwarkesh-s-fossil-fuel-analogy.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="preconnect" href="https://cdn.jsdelivr.net">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fontsource/iosevka@5.0.8/index.min.css">
  <link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://alexdong.com/feed.xml" title="Alex Dong&apos;s Blog" /></head><body><header class="site-header" role="banner">
  <div class="wrapper">
    <div style="text-align: center;">
      <a class="site-title" rel="author" href="/">Stream of Thoughts from Alex Dong</a>
      <p style="margin: 0; font-size: 0.875rem; color: var(--meta-color);">What I find interesting, intriguing or insightful</p>
    </div>
  </div>
</header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Dwarkesh&#39;s Fossil Fuel Analogy</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2025-10-06T22:35:00+13:00" itemprop="datePublished">Oct 6, 2025
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>Dwarkesh published a short <a href="https://www.dwarkesh.com/p/thoughts-on-sutton">follow-up</a> to his previous interview with Richard Sutton that I commented <a href="/thoughts-on-richard-sutton-s-interview-on-dwarkesh-podcast.html">extensively last week</a>.</p>

<p>I think Dwarkesh’s point on LLM may not be “the” right path forever, but it is definitely a path that we can keep exploring for a while, and maybe even take us to AGI or ASI. This doesn’t mean Sutton is wrong, but it does mean that we shouldn’t just dismiss LLM now and solely focus on RL.</p>

<p>The analogy Dwarkesh made is apt:</p>

<blockquote>
  <p>In a talk a few months ago, Ilya compared pretraining data to fossil fuels. This analogy has remarkable reach. Just because fossil fuels are not renewable does not mean that our civilization ended up on a dead-end track by using them. You simply couldn’t have transitioned from the water wheels in 1800 to solar panels and fusion power plants. We had to use this cheap, convenient, plentiful intermediary.</p>

  <p>AlphaGo (which was conditioned on human games) and AlphaZero (which was bootstrapped from scratch) were both superhuman Go players. AlphaZero was better.</p>

  <p>Will we (or the first AGIs) eventually come up with a general learning technique that requires no initialization of knowledge - that just bootstraps itself from the very start? And will it outperform the very best AIs that have been trained to that date? Probably yes.</p>

  <p>But does this mean that imitation learning must not play any role whatsoever in developing the first AGI, or even the first ASI? No. AlphaGo was still superhuman, despite being initially shepherded by human player data. The human data isn’t necessarily actively detrimental - at enough scale it just isn’t significantly helpful.</p>

  <p>The accumulation of knowledge over tens of thousands of years has clearly been essential to humanity’s success. In any field of knowledge, thousands (and likely millions) of previous people were involved in building up our understanding and passing it on to the next generation. We didn’t invent the language we speak, nor the legal system we use, nor even most of the knowledge relevant to the technologies in our phones. This process is more analogous to imitation learning than to RL from scratch.</p>
</blockquote>


  </div><footer class="post-footer">
      <nav class="post-categories" aria-label="Categories"><a class="post-category p-category" rel="tag" href="/categories/reinforcement-learning/">reinforcement-learning</a></nav>
    </footer><a class="u-url" href="/dwarkesh-s-fossil-fuel-analogy.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer">
  <div class="wrapper">
    <div style="text-align: center;">
      <a class="u-email" href="mailto:me@alexdong.com">me@alexdong.com</a>
    </div>
  </div>
</footer></body>

</html>
