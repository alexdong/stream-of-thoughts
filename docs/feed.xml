<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://alexdong.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://alexdong.com/" rel="alternate" type="text/html" /><updated>2025-10-17T15:43:08+13:00</updated><id>https://alexdong.com/feed.xml</id><title type="html">Alex Dong’s Blog</title><subtitle>Stream of Thoughts from Alex Dong. What I find interesting, intriguing or insightful.</subtitle><entry><title type="html">H100 offers 1.45x better value than A10G</title><link href="https://alexdong.com/h100-offers-1-45x-better-value-than-a10g.html" rel="alternate" type="text/html" title="H100 offers 1.45x better value than A10G" /><published>2025-10-14T08:31:00+13:00</published><updated>2025-10-14T08:31:00+13:00</updated><id>https://alexdong.com/h100-offers-1-45x-better-value-than-a10g</id><content type="html" xml:base="https://alexdong.com/h100-offers-1-45x-better-value-than-a10g.html"><![CDATA[<p>H100 is 7.5x faster but only 3.1x more expensive. 2.45x better value.</p>

<table>
  <thead>
    <tr>
      <th>GPU</th>
      <th style="text-align: right">Tokens/s</th>
      <th style="text-align: right">Tokens/hour</th>
      <th style="text-align: right">$/hour (SYD)</th>
      <th style="text-align: right">$ per 1M tokens</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>A10G</em></td>
      <td style="text-align: right">400</td>
      <td style="text-align: right">1.44M</td>
      <td style="text-align: right">$1.31</td>
      <td style="text-align: right"><em>~$0.91/M</em></td>
    </tr>
    <tr>
      <td><em>H100</em></td>
      <td style="text-align: right">3,000</td>
      <td style="text-align: right">10.8M</td>
      <td style="text-align: right">$4.00</td>
      <td style="text-align: right"><em>~$0.37/M</em></td>
    </tr>
  </tbody>
</table>]]></content><author><name></name></author><summary type="html"><![CDATA[H100 is 7.5x faster but only 3.1x more expensive. 2.45x better value.]]></summary></entry><entry><title type="html">Seeing like a Software Company - Celebrate Illegible Work</title><link href="https://alexdong.com/seeing-like-a-software-company-illegible-work.html" rel="alternate" type="text/html" title="Seeing like a Software Company - Celebrate Illegible Work" /><published>2025-10-11T23:07:00+13:00</published><updated>2025-10-11T23:07:00+13:00</updated><id>https://alexdong.com/seeing-like-a-software-company-illegible-work</id><content type="html" xml:base="https://alexdong.com/seeing-like-a-software-company-illegible-work.html"><![CDATA[<p>There are not many articles that capture the experience of working, or seeing your loved ones work, in a large software company like <a href="https://www.seangoedecke.com/seeing-like-a-software-company/">Seeing like a Software Company</a>.</p>

<p>This essay builds on the ideas from <a href="https://en.wikipedia.org/wiki/Seeing_Like_a_State">Seeing like a State</a> by James C. Scott. The key idea is that large organizations need to make work “legible” in order to manage it at scale. This often means breaking down complex tasks into simple, measurable, and standardized components. While this makes it easier to manage, it can also lead to a loss of nuance and a disconnect from the actual work being done.</p>

<blockquote>
  <p>Modern organizations exert control by maximising “legibility”: by altering the system so that all parts of it can be measured, reported on, and so on.
However, these organizations are dependent on a huge amount of “illegible” work: work that cannot be tracked or planned for, but is nonetheless essential.
Increasing legibility thus often actually lowers efficiency - but the other benefits are high enough that organizations are typically willing to do so regardless.</p>

  <p>James C. Scott was writing about the “high modernist” movement in governance that produced (among other things) the tidy German forests of the 19th century1. In order to produce wood at scale, the German state demanded legibility: forests that an inspector could visit to tally up the amount of healthy trees. That means that you must be able to walk through the forest - i.e. the underbrush must be controlled - and the trees ought to be ideally laid out in neat rows of a single type.</p>

  <p>Proponents of legibility often describe their processes as “efficiency measures” or ways to “avoid waste”. But overall, the new “efficient” forests were in fact far less efficient than the old, illegible forests. They produced less wood per year and required more effort to fight disease, because the underbrush proved surprisingly load-bearing to the health of the soil, and the variety of species turned out to have been an asset. The new homogeneous forests could be wiped out by a single parasite or disease in a way that the older, more varied forests could not.</p>

  <p>However, the advantages of legibility are enormous. Once you know exactly how many trees you have, you can plan ahead, make large trade deals, avoid graft, and so on. To me, this is the most interesting point Scott makes. Large organizations did genuinely think that more legibility would necessarily increase efficiency. But even when it became clear that that was false, those organizations continued pushing for legibility anyway, because the other advantages were too powerful.</p>

  <p>Why don’t large companies react to this by doing away with all of their processes? Are they stupid? No. The processes that slow engineers down are the same processes that make their work legible to the rest of the company. And that legibility (in dollar terms) is more valuable than being able to produce software more efficiently.</p>

  <p>Why are these capabilities so valuable to a large software company, when small software companies can do without them? This is leaving my area of expertise somewhat, but I’m pretty sure the main answer is large enterprise deals. Making deals with large enterprise customers is fantastically profitable. Any sufficiently large SaaS will thus pivot from small customers to enterprise customers, if it can. But enterprise deals (a) can take many, many months to set up, and (b) require making long-term feature commitments. An illegible company is not configured to be able to stick with a boring enterprise deal for many months, constantly answering questions and delivering features. Large enterprise customers simply won’t trust a small software company to deliver the things they need over the next year or two.</p>

  <p>Customers like this typically value legibility very highly, and so demand that their vendors also be legible. In fact, highly legible organizations struggle to communicate at all with organizations that are less legible (and vice versa). They don’t have access to the right bona fides, they don’t talk the same language, and so on. This puts real pressure on growing tech companies to become more legible, even if it hurts their ability to deliver software.</p>
</blockquote>]]></content><author><name></name></author><summary type="html"><![CDATA[There are not many articles that capture the experience of working, or seeing your loved ones work, in a large software company like Seeing like a Software Company.]]></summary></entry><entry><title type="html">Python@3.14t - First GIL-free Python</title><link href="https://alexdong.com/python-3-14t-first-gil-free-python.html" rel="alternate" type="text/html" title="Python@3.14t - First GIL-free Python" /><published>2025-10-10T22:47:00+13:00</published><updated>2025-10-10T22:47:00+13:00</updated><id>https://alexdong.com/python-3-14t-first-gil-free-python</id><content type="html" xml:base="https://alexdong.com/python-3-14t-first-gil-free-python.html"><![CDATA[<p>Python 3.14 finally released today. The biggest news is that this is the first GIL-free Python. Even though it’s slightly slower and it will have rough edges, this is a huge milestone for Python.</p>

<p>Besides the Free-Threaded Python news, there are a few other highlights worth mentioning:</p>
<ul>
  <li>Template strings: t-strings as <code class="language-plaintext highlighter-rouge">string.templatelib.Template</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">functools.Placeholder</code> that makes instantiating <code class="language-plaintext highlighter-rouge">partial</code> much easier</li>
  <li><code class="language-plaintext highlighter-rouge">concurrent.futures.InterpreterPoolExecutor</code> for parallelism without GIL</li>
  <li>Much improved REPL with syntax highlighting and autocompletion (these should have been in a long time ago!)</li>
</ul>

<p>For more details, see the <a href="https://docs.python.org/3.14/whatsnew/3.14.html">What’s New in Python 3.14</a> document.</p>]]></content><author><name></name></author><category term="python" /><summary type="html"><![CDATA[Python 3.14 finally released today. The biggest news is that this is the first GIL-free Python. Even though it’s slightly slower and it will have rough edges, this is a huge milestone for Python.]]></summary></entry><entry><title type="html">Cory Doctorow: Reverse Centaurs</title><link href="https://alexdong.com/cory-doctorow-reverse-centaurs.html" rel="alternate" type="text/html" title="Cory Doctorow: Reverse Centaurs" /><published>2025-10-09T22:20:00+13:00</published><updated>2025-10-09T22:20:00+13:00</updated><id>https://alexdong.com/cory-doctorow-reverse-centaurs</id><content type="html" xml:base="https://alexdong.com/cory-doctorow-reverse-centaurs.html"><![CDATA[<p>I picked up Cory Doctorow’s book <a href="https://craphound.com/radicalized/"><em>Radicalized</em></a> recently at the library. Doctorow has a knack for making you care about people in dramatically different social situations. It forced me to really feel for the characters who are on the receiving end of the ugly social impacts of technology “advancements”.</p>

<p>Doctorow said:</p>

<blockquote>
  <p>Science fiction’s superpower isn’t thinking up new technologies – it’s thinking up new social arrangements for technology. What the gadget does is nowhere near as important as who the gadget does it for and who it does it to. Your car can use a cutting-edge computer vision system to alert you when you’re drifting out of your lane – or it can use that same system to narc you out to your insurer so they can raise your premiums by $10 that month to punish you for inattentive driving. Same gadget, different social arrangement.</p>
</blockquote>

<p>Today I stumbled upon another piece titled <a href="https://locusmag.com/feature/commentary-cory-doctorow-reverse-centaurs/"><em>Reverse Centaurs</em></a>. This is a very short and poignant essay that provides a fresh perspective on why we are getting such a dramatically different experience of AI.</p>

<p>The key idea? Be a centaur, not a reverse centaur. A centaur is a human powered by a machine, while a reverse centaur is a machine served by a human who no longer has agency. Their job is to take the blame for the machine’s mistakes.</p>

<blockquote>
  <p>A centaur is a human being who is assisted by a machine that does some onerous task (like transcribing 40 hours of podcasts). A reverse-centaur is a machine that is assisted by a human being, who is expected to work at the machine’s pace. That would be Buscaglia: who was given an assignment to do the work of 50 or more people, on a short timescale, and a shoestring budget.</p>

  <p>When you give a freelancer an assignment to turn around ten summer lists on a short timescale, everyone understands that his job isn’t to write those lists, it’s to supervise a chatbot.</p>

  <p>But his job wasn’t even to supervise the chatbot adequately (single-handedly fact-checking 10 lists of 15 items is a long, labor-intensive pro­cess). Rather, it was to take the blame for the factual inaccuracies in those lists. He was, in the phrasing of Dan Davies, “an accountability sink” (or as Madeleine Clare Elish puts it, a “moral crumple zone”).</p>

  <p>When I used Whisper to transcribe a folder full of MP3s, that was me being a centaur. When Buscaglia was assigned to oversee a chatbot’s error-strewn, 64-page collection of summer lists, on a short timescale and at short pay, with him and him alone bearing the blame for any errors that slipped through, that was him being a reverse-centaur.</p>
</blockquote>]]></content><author><name></name></author><category term="social-impact" /><category term="books" /><summary type="html"><![CDATA[I picked up Cory Doctorow’s book Radicalized recently at the library. Doctorow has a knack for making you care about people in dramatically different social situations. It forced me to really feel for the characters who are on the receiving end of the ugly social impacts of technology “advancements”.]]></summary></entry><entry><title type="html">AI as a Copilot for Mathematical Discovery</title><link href="https://alexdong.com/ai-as-a-copilot-for-mathematical-discovery.html" rel="alternate" type="text/html" title="AI as a Copilot for Mathematical Discovery" /><published>2025-10-08T21:57:00+13:00</published><updated>2025-10-08T21:57:00+13:00</updated><id>https://alexdong.com/ai-as-a-copilot-for-mathematical-discovery</id><content type="html" xml:base="https://alexdong.com/ai-as-a-copilot-for-mathematical-discovery.html"><![CDATA[<p><a href="https://epochai.substack.com/p/ai-can-now-do-math-but-can-it-ask?utm_source=post-email-title&amp;publication_id=3755861&amp;post_id=175540105">Epoch AI’s recent interview with Ken Ono</a> was a fascinating read. Ono, a mathematician at University of Virginia, discussed in greater detail on how AI is transforming mathematical research. It’s a long interview and here are some highlights:</p>

<blockquote>
  <p>Q: What makes the problem hard for an AI?
A: It’s very difficult to predict which problems are the difficult ones.</p>
</blockquote>

<blockquote>
  <p>Q: What have we learned about AI’s ability? 
A: I don’t think I can ask a question that AI can’t identify with a particular area of mathematics, because it seems like ChatGPT and others just have at their fingertips the accumulation of human knowledge. And it continues to surprise me how quickly that seems to be the case. Three years ago, ChatGPT or all of these large language models would get things wrong that a five year old could get right. And now we’re asking questions that a PhD student at our universities wouldn’t even know where to start to look.</p>
</blockquote>

<blockquote>
  <p>Q: Extending into the future, where do you expect AI to land in math, say, three years?
A: When the participants, at the Frontier Math Symposium, see and test out the pro version of ChatGPT that has been provided to us, you can see their eyes light up thinking it is amazing. This could be really, genuinely my copilot. But perhaps the bigger deal will be the realization for the mathematicians that are here and the colleagues, when we all go back to our universities, that AI is really meant to be a copilot. And will it assist our scientific discovery? Absolutely.</p>
</blockquote>

<blockquote>
  <p>Q: Do you use AI in your research?
A: … as a theoretical device, the computers help us discover an area of mathematics that I don’t think any of us thought would exist. So that’s a good partner. A good partner is one that is going to give you clues to conjectures that you can then either prove or build a body of work from.</p>
</blockquote>

<blockquote>
  <p>Q: And how much do you expect AI to reshape math research where zero on a scale from 0 to 10, where zero is the level of a pocket calculator and then ten is math researchers are obsolete.
A: Well, I don’t think math researchers will ever be obsolete because an AI doesn’t know how to generate good questions. If that happens, well, that would be really a profound moment. … Asking good questions that drive a theory takes skill. And I think we will always need people who can do that. And we don’t have many people who can do that. These are generally very special people.</p>
</blockquote>]]></content><author><name></name></author><summary type="html"><![CDATA[Epoch AI’s recent interview with Ken Ono was a fascinating read. Ono, a mathematician at University of Virginia, discussed in greater detail on how AI is transforming mathematical research. It’s a long interview and here are some highlights:]]></summary></entry><entry><title type="html">Inspect AI</title><link href="https://alexdong.com/inspect-ai.html" rel="alternate" type="text/html" title="Inspect AI" /><published>2025-10-07T21:24:00+13:00</published><updated>2025-10-07T21:24:00+13:00</updated><id>https://alexdong.com/inspect-ai</id><content type="html" xml:base="https://alexdong.com/inspect-ai.html"><![CDATA[<p><a href="https://x.com/joecole">Joe</a> mentioned the new <a href="https://safety-research.github.io/petri/">Petri Alignment
tool</a> from Anthropic. As I read
through the GitHub repo, I was surprised to find how simple the code is. As I
dug deeper, I realized it’s actually a plugin for Inspect AI, an open-source
Python project by the UK’s AI Security Institute.</p>

<p>Inspect AI provides scaffolding for evaluating LLMs. I was pleasantly
surprised to see just how many advanced features are already in place:</p>

<ul>
  <li>Execution: <a href="https://inspect.aisi.org.uk/caching.html">provider caching</a>,
<a href="https://inspect.aisi.org.uk/parallelism.html">parallelism for multiple models, benchmarks, or
requests</a>, and
<a href="https://inspect.aisi.org.uk/sandboxing.html">sandboxing across Docker, EC2, or
Proxmox</a></li>
  <li>Debugging: <a href="https://inspect.aisi.org.uk/tracing.html">tracing</a> and tidy <a href="https://inspect.aisi.org.uk/log-viewer.html">log
viewers</a></li>
  <li>Output: built-in <a href="https://inspect.aisi.org.uk/structured.html">Pydantic structured
validation</a> and <a href="https://inspect.aisi.org.uk/typing.html">typed store</a></li>
</ul>

<p>All I need to supply are three ingredients:</p>

<ol>
  <li><a href="https://inspect.aisi.org.uk/datasets.html">Datasets</a> — CSV files with
<code class="language-plaintext highlighter-rouge">id</code>, <code class="language-plaintext highlighter-rouge">input</code>, and <code class="language-plaintext highlighter-rouge">target</code> columns.</li>
  <li><a href="https://inspect.aisi.org.uk/reference/inspect_ai.solver.html#generation">Solvers</a>
— chains of Python functions that take the input and produce the model’s
output.</li>
  <li><a href="https://inspect.aisi.org.uk/reference/inspect_ai.scorer.html">Scorers</a> —
metrics that turn those outputs into scores. Regular expressions, F1,
statistics like <code class="language-plaintext highlighter-rouge">std</code> or <code class="language-plaintext highlighter-rouge">stderr</code>, and even LLM-as-Judge are ready to go.</li>
</ol>

<p>The tool is well documented, strongly typed, and actively maintained. Next up I
want to use it to rewrite some of the benchmarks end-to-end and see how easily I can
extend it to support more complex evaluation workflows.</p>]]></content><author><name></name></author><category term="eval" /><summary type="html"><![CDATA[Joe mentioned the new Petri Alignment tool from Anthropic. As I read through the GitHub repo, I was surprised to find how simple the code is. As I dug deeper, I realized it’s actually a plugin for Inspect AI, an open-source Python project by the UK’s AI Security Institute.]]></summary></entry><entry><title type="html">Dwarkesh’s Fossil Fuel Analogy</title><link href="https://alexdong.com/dwarkesh-s-fossil-fuel-analogy.html" rel="alternate" type="text/html" title="Dwarkesh’s Fossil Fuel Analogy" /><published>2025-10-06T22:35:00+13:00</published><updated>2025-10-06T22:35:00+13:00</updated><id>https://alexdong.com/dwarkesh-s-fossil-fuel-analogy</id><content type="html" xml:base="https://alexdong.com/dwarkesh-s-fossil-fuel-analogy.html"><![CDATA[<p>Dwarkesh published a short <a href="https://www.dwarkesh.com/p/thoughts-on-sutton">follow-up</a> to his previous interview with Richard Sutton that I commented <a href="/thoughts-on-richard-sutton-s-interview-on-dwarkesh-podcast.html">extensively last week</a>.</p>

<p>I think Dwarkesh’s point on LLM may not be “the” right path forever, but it is definitely a path that we can keep exploring for a while, and maybe even take us to AGI or ASI. This doesn’t mean Sutton is wrong, but it does mean that we shouldn’t just dismiss LLM now and solely focus on RL.</p>

<p>The analogy Dwarkesh made is apt:</p>

<blockquote>
  <p>In a talk a few months ago, Ilya compared pretraining data to fossil fuels. This analogy has remarkable reach. Just because fossil fuels are not renewable does not mean that our civilization ended up on a dead-end track by using them. You simply couldn’t have transitioned from the water wheels in 1800 to solar panels and fusion power plants. We had to use this cheap, convenient, plentiful intermediary.</p>

  <p>AlphaGo (which was conditioned on human games) and AlphaZero (which was bootstrapped from scratch) were both superhuman Go players. AlphaZero was better.</p>

  <p>Will we (or the first AGIs) eventually come up with a general learning technique that requires no initialization of knowledge - that just bootstraps itself from the very start? And will it outperform the very best AIs that have been trained to that date? Probably yes.</p>

  <p>But does this mean that imitation learning must not play any role whatsoever in developing the first AGI, or even the first ASI? No. AlphaGo was still superhuman, despite being initially shepherded by human player data. The human data isn’t necessarily actively detrimental - at enough scale it just isn’t significantly helpful.</p>

  <p>The accumulation of knowledge over tens of thousands of years has clearly been essential to humanity’s success. In any field of knowledge, thousands (and likely millions) of previous people were involved in building up our understanding and passing it on to the next generation. We didn’t invent the language we speak, nor the legal system we use, nor even most of the knowledge relevant to the technologies in our phones. This process is more analogous to imitation learning than to RL from scratch.</p>
</blockquote>]]></content><author><name></name></author><category term="reinforcement-learning" /><summary type="html"><![CDATA[Dwarkesh published a short follow-up to his previous interview with Richard Sutton that I commented extensively last week.]]></summary></entry><entry><title type="html">Earth was born dry until a cosmic collision made it a blue planet</title><link href="https://alexdong.com/earth-was-born-dry-until-a-cosmic-collision-made-it-a-blue-planet.html" rel="alternate" type="text/html" title="Earth was born dry until a cosmic collision made it a blue planet" /><published>2025-10-05T22:47:00+13:00</published><updated>2025-10-05T22:47:00+13:00</updated><id>https://alexdong.com/earth-was-born-dry-until-a-cosmic-collision-made-it-a-blue-planet</id><content type="html" xml:base="https://alexdong.com/earth-was-born-dry-until-a-cosmic-collision-made-it-a-blue-planet.html"><![CDATA[<p>From <a href="https://www.sciencedaily.com/releases/2025/09/250928095654.htm">Science Daily</a></p>

<blockquote>
  <p>Scientists have shown that Earth’s basic chemistry solidified within just
three million years of the Solar System’s formation. Initially, the planet
was barren and inhospitable, missing water and carbon compounds. A colossal
collision with Theia likely changed everything, bringing the essential
ingredients for life. The study highlights that habitability may hinge on
rare chance events.</p>
</blockquote>]]></content><author><name></name></author><category term="cool-science" /><summary type="html"><![CDATA[From Science Daily]]></summary></entry><entry><title type="html">Pavel Durov’s interview with Lex Fridman</title><link href="https://alexdong.com/pavel-durov-s-interview-with-lex-fridman.html" rel="alternate" type="text/html" title="Pavel Durov’s interview with Lex Fridman" /><published>2025-10-04T18:30:00+13:00</published><updated>2025-10-04T18:30:00+13:00</updated><id>https://alexdong.com/pavel-durov-s-interview-with-lex-fridman</id><content type="html" xml:base="https://alexdong.com/pavel-durov-s-interview-with-lex-fridman.html"><![CDATA[<p>Pavel’s sincerity (when he recounted the interaction with the French Intelligence service), strong ethical foundation (when asked about what would happen if he is sentenced to 20 years in prison, he said he would starve to death to “reboot” the game rather than give in), and his slow, precise, and deliberate responses are a fresh breeze in an industry that has so much hot air.</p>

<p>I am a fan.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/qjPH9njnaVU?si=JnSWhbkusfcuulmd" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>]]></content><author><name></name></author><summary type="html"><![CDATA[Pavel’s sincerity (when he recounted the interaction with the French Intelligence service), strong ethical foundation (when asked about what would happen if he is sentenced to 20 years in prison, he said he would starve to death to “reboot” the game rather than give in), and his slow, precise, and deliberate responses are a fresh breeze in an industry that has so much hot air.]]></summary></entry><entry><title type="html">Agentic Loop Design - Tool #1: Long-Term Memory that Survives Resets</title><link href="https://alexdong.com/agentic-loop-design-long-term-memory-and-resets.html" rel="alternate" type="text/html" title="Agentic Loop Design - Tool #1: Long-Term Memory that Survives Resets" /><published>2025-10-03T19:20:00+13:00</published><updated>2025-10-03T19:20:00+13:00</updated><id>https://alexdong.com/agentic-loop-design-long-term-memory-and-resets</id><content type="html" xml:base="https://alexdong.com/agentic-loop-design-long-term-memory-and-resets.html"><![CDATA[<p>When a session drags on and the context window fills up, I often watch the
models start to get lazy. They drop earlier decisions, skim the edges, and
sometimes declare “all tests are passing” after touching only part of the
suite.</p>

<p>Both Codex and Claude Code ship a <code class="language-plaintext highlighter-rouge">/compact</code> command that compresses,
summarizes, and trims conversation history to make room for new messages. In
practice, the compaction drops enough detail that I reach for it less and less.</p>

<p>We need a way to reset the conversation without losing the continuity of the
work. We need a tool that lets us restart often and still remember what we were
doing and where we left off. There have been many attempts at “Context
Compression,” but none have worked well enough yet.</p>

<p>That tool is a plaintext <code class="language-plaintext highlighter-rouge">PLAN.md</code>. As the model cycles through the
design-plan-implement loop, it appends and updates this file, then re-reads it
at the start of every new session.</p>

<p>Here’s the scaffold I use.</p>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gu">## What and Why</span>
<span class="nt">&lt;</span><span class="err">!,</span>  <span class="na">define</span> <span class="na">the</span> <span class="na">what</span><span class="err">,</span> <span class="na">why</span><span class="err">,</span> <span class="na">scope</span> <span class="err">,</span> <span class="nt">&gt;</span>

<span class="gu">## Observation</span>
<span class="nt">&lt;</span><span class="err">!,</span>  <span class="na">facts</span> <span class="na">only</span> <span class="na">from</span> <span class="na">Observation.</span> <span class="na">Research.</span> <span class="na">Note</span> <span class="na">down</span> <span class="na">relevant</span> <span class="na">facts.</span> <span class="err">,</span> <span class="nt">&gt;</span>

<span class="gu">## Design</span>
<span class="nt">&lt;</span><span class="err">!,</span>  <span class="na">chosen</span> <span class="na">shapes</span> <span class="err">&amp;</span> <span class="na">interfaces</span><span class="err">;</span> <span class="na">proposed</span> <span class="na">options</span> <span class="na">when</span> <span class="na">there</span> <span class="na">are</span> <span class="na">real</span> <span class="na">trade-offs</span> <span class="err">,</span> <span class="nt">&gt;</span>

<span class="gu">## Plan</span>
<span class="nt">&lt;</span><span class="err">!,</span>  <span class="na">five-minute</span> <span class="na">tasks</span> <span class="na">with</span> <span class="err">[</span> <span class="err">]</span> <span class="na">checkboxes</span> <span class="na">and</span> <span class="na">nested</span> <span class="na">numbering</span> <span class="err">,</span> <span class="nt">&gt;</span>
</code></pre></div></div>

<p>Running the loop means cycling through four passes. After each pass I ask the
model to capture the discussion, note the details, and record the conclusions
in PLAN.md, then spin up a fresh session. The file becomes the single source of
truth the agent must consult before touching anything.</p>

<p>Here are the prompts I use for each phase.</p>

<h2 id="what-and-why">What and Why</h2>

<p>I start by anchoring the change in plain language so the model and I share the
same target and boundaries.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Task: Refresh the "## What and Why" section in ./plans/PLAN-{slug}.md for "{brief change name}".

Steps:
1. Describe the change in 1–2 sentences.
1. Clarify why it matters now.
2. Capture scope boundaries: what is in/out, success measures.
3. List open questions that block commitment; ask me for any missing context.

Guardrails:
- No solution or implementation steps.
- Write in tight paragraphs or focused bullet points.
- Stop after the Why section is updated.
</code></pre></div></div>

<h2 id="observation">Observation</h2>

<p>Once the intent is locked, the next pass is a fact-finding sweep. No edits, no plans.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Task: Compile the Observation section for the changes described in `## What and Why`.

Read ./plans/PLAN-{slug}.md first, then browse, research, and note down facts.

Deliverable:
- Append under "## Observation".
- One bullet per relevant file, symbol, or endpoint: location + behavior in 1–2 sentences.
- Close with "Risks &amp; brittle spots" listing edge cases or debt (facts only).

Scope to inspect:
- Code/config touching the affected data or control paths.
- Schemas/migrations, jobs, CLIs, scripts, docs, and tests relying on current behavior.
- External integrations, rate limits, feature flags, and environment switches.

Guardrails:
- Mark uncertain items with "?" rather than omitting them.
- Do not edit code or propose changes.
- Stop after Observation is complete.
- Be thorough and methodical. Go through the files one by one.
</code></pre></div></div>

<h2 id="design">Design</h2>

<p>With the facts in place, we move into the design phase and ask for options,
trade-off analysis, and key code snippets.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Task: Draft the Design section for "What" using the "Observation" in ./plans/PLAN-{slug}.md.

Deliverable:
- Append under "## Design" in PLAN-{slug}.md.
- Describe chosen data flows, interfaces, and storage, naming concrete functions/types.
- When trade-offs exist, list 2–3 options with crisp pros/cons before recommending one.
- End with "Implications for tests" describing what must be covered.
- Include just enough code snippets to show the high-level design.

Guardrails:
- Ground every decision in Observation facts or clearly stated assumptions.
- No implementation details below the interface level.
- Stop after Design is complete.
</code></pre></div></div>

<h2 id="plan">Plan</h2>

<p>The design turns into an execution checklist: small, verifiable moves that keep
the loop tight.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Task: Translate the Design for "{brief change name}" into an execution plan.

Deliverable:
- Append under "## Plan" in PLAN-{slug}.md with checkbox tasks.
- Keep tasks to five-minute chunks; nest numbered substeps if needed.
- Include "Tests (fit)" for each task describing what must be verified before coding.

Order of operations:
1. Types/constants and contracts.
2. Write/update data producers.
3. Read paths/consumers.
4. Data migrations/backfills.
5. Clean-up and docs.

Guardrails:
- Highlight removals/renames and search/replace surfaces explicitly.
- Stop after the Plan section is written.
</code></pre></div></div>

<h2 id="implement">Implement</h2>

<p>Implementation finally pulls a single checkbox off the plan and runs it to
completion before coming up for air.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>We are now implementing the tasks from the PLAN-{slug}.md file.

Execute the following tasks in order.
&gt; {paste the exact checkbox line}

Execution rules:
- Begin with the task's Tests, write or adjust checks first.
- Make the smallest code changes needed to satisfy those tests.
- Run the standard project checks (`make lint`, `make test`) and report results.
- If anything fails, even outside touched areas, resolve it before stopping.
- Review the changes and rewrite the code changes to improve clarity or efficiency.
- Keep rewriting until no further improvements are possible.
- Check off the task only when all tests pass and the code is clean.
- Do not pull another task once this one closes.
</code></pre></div></div>

<p>This rhythm, write, compact, reset, load from PLAN.md, keeps the agent
sharp even on long-running task. Each task gets to benefit from the 
full context window, and the model never has to guess what it was doing
last time.</p>]]></content><author><name></name></author><category term="agentic" /><category term="software-design" /><summary type="html"><![CDATA[When a session drags on and the context window fills up, I often watch the models start to get lazy. They drop earlier decisions, skim the edges, and sometimes declare “all tests are passing” after touching only part of the suite.]]></summary></entry></feed>