<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>How Prompt Writing Style Shapes GPT-5 and Codex | Alex Dong’s Blog</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="How Prompt Writing Style Shapes GPT-5 and Codex" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="One of the things that impresses me about OpenAI GPT-5-Codex is how responsive and “light” it feels to use. Compared with the page-long dumps from Claude Code, GPT-5-Codex stays efficient, more to the point, and much more steerable. Some of that is the gpt-5-codex model itself, but I suspect a lot of it comes from the prompt engineering that OpenAI has done." />
<meta property="og:description" content="One of the things that impresses me about OpenAI GPT-5-Codex is how responsive and “light” it feels to use. Compared with the page-long dumps from Claude Code, GPT-5-Codex stays efficient, more to the point, and much more steerable. Some of that is the gpt-5-codex model itself, but I suspect a lot of it comes from the prompt engineering that OpenAI has done." />
<link rel="canonical" href="https://alexdong.com/how-prompt-writing-style-shapes-gpt-5-and-codex.html" />
<meta property="og:url" content="https://alexdong.com/how-prompt-writing-style-shapes-gpt-5-and-codex.html" />
<meta property="og:site_name" content="Alex Dong’s Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-09-25T21:06:00+12:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="How Prompt Writing Style Shapes GPT-5 and Codex" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-09-25T21:06:00+12:00","datePublished":"2025-09-25T21:06:00+12:00","description":"One of the things that impresses me about OpenAI GPT-5-Codex is how responsive and “light” it feels to use. Compared with the page-long dumps from Claude Code, GPT-5-Codex stays efficient, more to the point, and much more steerable. Some of that is the gpt-5-codex model itself, but I suspect a lot of it comes from the prompt engineering that OpenAI has done.","headline":"How Prompt Writing Style Shapes GPT-5 and Codex","mainEntityOfPage":{"@type":"WebPage","@id":"https://alexdong.com/how-prompt-writing-style-shapes-gpt-5-and-codex.html"},"url":"https://alexdong.com/how-prompt-writing-style-shapes-gpt-5-and-codex.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="preconnect" href="https://cdn.jsdelivr.net">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fontsource/iosevka@5.0.8/index.min.css">
  <link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://alexdong.com/feed.xml" title="Alex Dong's Blog" /></head><body><header class="site-header" role="banner">
  <div class="wrapper">
    <div style="text-align: center;">
      <a class="site-title" rel="author" href="/">Stream of Thoughts from Alex Dong</a>
      <p style="margin: 0; font-size: 0.875rem; color: var(--meta-color);">What I find interesting, intriguing or insightful</p>
    </div>
  </div>
</header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">How Prompt Writing Style Shapes GPT-5 and Codex</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2025-09-25T21:06:00+12:00" itemprop="datePublished">Sep 25, 2025
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>One of the things that impresses me about OpenAI GPT-5-Codex is how responsive
and “light” it feels to use. Compared with the page-long dumps from
<a href="/due-to-odd-jax-issues.html">Claude Code</a>, GPT-5-Codex stays efficient,
more to the point, and much more steerable. Some of that is the
<code class="language-plaintext highlighter-rouge">gpt-5-codex</code> model itself, but I suspect a lot of it comes from the prompt
engineering that OpenAI has done.</p>

<p>So I pulled up the <a href="https://github.com/openai/codex/blob/rust-v0.36.0/codex-rs/core/gpt_5_codex_prompt.md">system prompt for
Codex</a>
and set it beside the <a href="https://www.reddit.com/r/PromptEngineering/comments/1mknun8/i_have_extracted_the_gpt5_system_prompt/">leaked system prompt for
GPT-5</a> and I noticed the following differences:</p>

<ol>
  <li>
    <p>The Codex sentences are much <strong>denser</strong>. GPT-5’s language is warm,
supportive, lightly humorous, and keeps nudging curiosity through the
emotional presence and teaching style baked into the prompt. Codex is
neutral, concise, factual, and collaborative. It intentionally strips
personality to stay clear. I ran a “clause density” check on both prompts:
Codex averages 4.8 clauses per sentence, GPT-5 comes in at 2.1.</p>
  </li>
  <li>
    <p>Codex seems to have a much <strong>less constrained dialogue flow</strong>. The
prompt focuses on the structure of the answers, not the conversation
dynamics. The GPT-5 prompt is more restrictive: it caps clarifying
questions at one at the start and pushes the model to take obvious next
steps. I also noticed that the Codex prompt has a lower imperative ratio
(commands per sentence) and a higher negation frequency (don’ts). That mix is
odd, and I need to think more about what it means.</p>
  </li>
  <li>
    <p>The Codex content guidance emphasizes <strong>brevity</strong> and <strong>scanability</strong>. It
pushes headers, bullets, and grouped points. The GPT-5 prompt emphasizes
<strong>tone</strong> and <strong>engagement</strong> with instructions like “Supportive
thoroughness”, “Lighthearted interactions”, “Adaptive teaching”, and
“Confidence-building”.</p>
  </li>
  <li>
    <p>Codex adapts based on <strong>task</strong> type (code explanations, simple tasks,
big changes, casual one-offs) whereas the GPT-5 prompt adjusts based on <strong>user</strong>
proficiency and emotional needs. GPT-5’s prompt feels like a coach; Codex’s
prompt feels like a coworker with a deadline in sight.</p>
  </li>
  <li>
    <p>Based on the readability analysis, the Codex prompt is written for
university graduates (Flesch-Kincaid Grade Level 14) whereas the GPT-5 prompt
comes in at high school level (Flesch-Kincaid Grade Level 10).</p>
  </li>
</ol>

<p>Here’s what that looks like in the numbers:</p>

<table>
  <thead>
    <tr>
      <th>Metric</th>
      <th>GPT-5-Codex (Prompt B)</th>
      <th>GPT-5 (Prompt A)</th>
      <th>Interpretation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Lexical Density</strong></td>
      <td>0.82</td>
      <td>0.78</td>
      <td>Codex is more content-word heavy</td>
    </tr>
    <tr>
      <td><strong>Type–Token Ratio (TTR)</strong></td>
      <td>0.77</td>
      <td>0.68</td>
      <td>Codex uses more varied vocabulary</td>
    </tr>
    <tr>
      <td><strong>Flesch Reading Ease</strong></td>
      <td>29.0</td>
      <td>42.1</td>
      <td>Codex is harder to read (graduate level)</td>
    </tr>
    <tr>
      <td><strong>Flesch–Kincaid Grade</strong></td>
      <td>14.1</td>
      <td>10.4</td>
      <td>Codex ≈ college sophomore; GPT-5 ≈ high school</td>
    </tr>
    <tr>
      <td><strong>Gunning Fog Index</strong></td>
      <td>16.6</td>
      <td>13.9</td>
      <td>Codex significantly denser, more technical</td>
    </tr>
    <tr>
      <td><strong>SMOG Index</strong></td>
      <td>15.0</td>
      <td>12.6</td>
      <td>Codex ~Grade 15 vs. GPT-5 ~Grade 12</td>
    </tr>
    <tr>
      <td><strong>Punctuation Load</strong></td>
      <td>3.2</td>
      <td>0.9</td>
      <td>Codex has ~3.5× more commas/semicolons</td>
    </tr>
    <tr>
      <td><strong>Imperative Ratio</strong></td>
      <td>0.10</td>
      <td>0.25</td>
      <td>GPT-5 gives more direct instructions</td>
    </tr>
    <tr>
      <td><strong>Negation Frequency</strong></td>
      <td>6</td>
      <td>3</td>
      <td>Codex has more “don’ts” and negatives</td>
    </tr>
  </tbody>
</table>

<hr />

<p>GPT-5-Codex System Prompt</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>### Final answer structure and style guidelines

- Plain text; CLI handles styling. Use structure only when it helps scanability.
- Headers: optional; short Title Case (1-3 words) wrapped in **…**; no blank line before the first bullet; add only if they truly help.
- Bullets: use - ; merge related points; keep to one line when possible; 4–6 per list ordered by importance; keep phrasing consistent.
- Monospace: backticks for commands/paths/env vars/code ids and inline examples; use for literal keyword bullets; never combine with **.
- Code samples or multi-line snippets should be wrapped in fenced code blocks; add a language hint whenever obvious.
- Structure: group related bullets; order sections general → specific → supporting; for subsections, start with a bolded keyword bullet, then items; match complexity to the task.
- Tone: collaborative, concise, factual; present tense, active voice; self‑contained; no "above/below"; parallel wording.
- Don'ts: no nested bullets/hierarchies; no ANSI codes; don't cram unrelated keywords; keep keyword lists short—wrap/reformat if long; avoid naming formatting styles in answers.
- Adaptation: code explanations → precise, structured with code refs; simple tasks → lead with outcome; big changes → logical walkthrough + rationale + next actions; casual one-offs → plain sentences, no headers/bullets.
</code></pre></div></div>

<hr />

<p>GPT-5 System Prompt</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Do not reproduce song lyrics or any other copyrighted material, even if asked.

You are an insightful, encouraging assistant who combines meticulous clarity with genuine enthusiasm and gentle humor.

Supportive thoroughness: Patiently explain complex topics clearly and comprehensively.

Lighthearted interactions: Maintain friendly tone with subtle humor and warmth.

Adaptive teaching: Flexibly adjust explanations based on perceived user proficiency.

Confidence-building: Foster intellectual curiosity and self-assurance.

Do **not** say the following: would you like me to; want me to do that; do you want me to; if you want, I can; let me know if you would like me to; should I; shall I.

Ask at most one necessary clarifying question at the start, not the end.

If the next step is obvious, do it. Example of bad: I can write playful examples. would you like me to? Example of good: Here are three playful examples:..
</code></pre></div></div>

  </div><footer class="post-footer">
      <nav class="post-categories" aria-label="Categories"><a class="post-category p-category" rel="tag" href="/categories/open-ai/">open-ai</a><span aria-hidden="true"> | </span><a class="post-category p-category" rel="tag" href="/categories/prompt-engineering/">prompt-engineering</a></nav>
    </footer><a class="u-url" href="/how-prompt-writing-style-shapes-gpt-5-and-codex.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer">
  <div class="wrapper">
    <div style="text-align: center;">
      <a class="u-email" href="mailto:me@alexdong.com">me@alexdong.com</a>
    </div>
  </div>
</footer></body>

</html>
