---
layout: post
title: "Three great virtues of an AI-assisted programmer"
date: 2025-08-04 14:00
comments: true
categories: 
---

Twenty years ago, when I first encountered Larry Wall's declaration that laziness, impatience, and hubris are the three great virtues of a programmer, it crystallised something I'd observed but couldn't articulate. These weren't character flaws—they were evolutionary advantages. Laziness drove us to automate the mundane. Impatience pushed us toward elegant solutions. Hubris made us believe we could solve problems others couldn't.

Today, with AI coding assistants generating functions faster than we can type, Wall's virtues feel like relics from a different era. When GitHub Copilot can autocomplete entire algorithms and ChatGPT can architect systems from scratch, what virtues should guide us?

Sean Goedecke proposes a compelling answer. He argues that AI-assisted programmers need fundamentally different virtues:
> - Obsession to keep your own mind working at the problem
> - Impatience to eject and work it out yourself
> - Suspicious of what the AI is doing

This shift reveals something profound about how AI transforms programming. Where Wall's virtues optimised for creation, Goedecke's optimise for curation. The challenge isn't writing code anymore—it's maintaining intellectual ownership of the solution.

Consider obsession. In the pre-AI era, we could afford mental shortcuts because the act of typing forced us to think. Now, with AI eagerly completing our half-formed thoughts, maintaining deep engagement requires deliberate effort. I've watched developers become passengers in their own codebases, accepting AI suggestions without truly understanding the implications.

Impatience takes on new meaning too. It's no longer about rushing to implement—it's about knowing when to abandon the AI and trust your instincts. The most effective AI-assisted developers I know have developed a sixth sense for when the conversation with AI has become counterproductive. They cut their losses quickly and code directly.

And suspicion? This might be the most critical virtue. AI doesn't just make mistakes—it makes plausible mistakes. It generates code that looks right, passes initial tests, but harbours subtle bugs or architectural flaws that surface months later. The developers who thrive are those who treat AI output like they would treat code from an overconfident junior developer: potentially useful, but requiring careful review.

These new virtues pose a challenge for organisations. How do you identify these qualities in candidates? Traditional coding interviews test for Wall's virtues—can you solve this problem efficiently? But testing for Goedecke's virtues requires different approaches entirely.

You can't gauge obsession through a whiteboard exercise. You can't measure productive impatience in a take-home assignment. And you certainly can't assess healthy suspicion when candidates aren't using AI tools during the interview process.

The companies that figure this out first will have a significant advantage. They'll build teams that harness AI's power without surrendering their ability to think deeply about problems. They'll ship faster without accumulating technical debt from uncritically accepted AI suggestions.

For now, the best approach might be to look for evidence of these virtues in how candidates describe their past work. Do they talk about diving deep into problems even when AI offered quick solutions? Can they articulate moments when they rejected AI assistance? Do they demonstrate understanding of AI's limitations alongside its capabilities?

The transition from Wall's virtues to Goedecke's represents more than a shift in programming practice—it's a fundamental reimagining of what it means to be a technologist in an AI-augmented world.

From: [Three great virtues of an AI-assisted programmer](https://www.seangoedecke.com/llm-user-virtues/)
