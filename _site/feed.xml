<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-08-04T15:05:15+12:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Alex Dong’s Blog</title><subtitle>Stream of thoughts from Alex Dong. What I find interesting, intriguing or insightful.</subtitle><entry><title type="html">Three great virtues of an AI-assisted programmer</title><link href="http://localhost:4000/2025/08/04/three-great-virtues-of-an-ai-assisted-programmer.html" rel="alternate" type="text/html" title="Three great virtues of an AI-assisted programmer" /><published>2025-08-04T14:00:00+12:00</published><updated>2025-08-04T14:00:00+12:00</updated><id>http://localhost:4000/2025/08/04/three-great-virtues-of-an-ai-assisted-programmer</id><content type="html" xml:base="http://localhost:4000/2025/08/04/three-great-virtues-of-an-ai-assisted-programmer.html"><![CDATA[Larry Wall famously declared that laziness, impatience, and hubris are the three great virtues of a
programmer. These qualities drive us to automate repetitive tasks, build efficient solutions, and
write maintainable code. 

But what happens when AI enters the picture?

Sean Goedecke suggests that AI-assisted programmers need different virtues:
> - Obsession to keep your own mind working at the problem
> - Impatience to eject and work it out yourself
> - Suspicious of what the AI is doing

Now, how can you find these out in a traditional job interview? You can't.

From: [Three great virtues of an AI-assisted programmer](https://www.seangoedecke.com/llm-user-virtues/)]]></content><author><name></name></author><summary type="html"><![CDATA[Larry Wall famously declared that laziness, impatience, and hubris are the three great virtues of a programmer. These qualities drive us to automate repetitive tasks, build efficient solutions, and write maintainable code.]]></summary></entry><entry><title type="html">Qwen3-30B: The Open Source AI Model That Changes On-Premises Deployment Economics</title><link href="http://localhost:4000/local-ai/2025/08/01/qwen3-30b-a3b-the-new-choice-for-nz-organizations-prioritizing-data-sovereignty.html" rel="alternate" type="text/html" title="Qwen3-30B: The Open Source AI Model That Changes On-Premises Deployment Economics" /><published>2025-08-01T14:30:00+12:00</published><updated>2025-08-01T14:30:00+12:00</updated><id>http://localhost:4000/local-ai/2025/08/01/qwen3-30b-a3b-the-new-choice-for-nz-organizations-prioritizing-data-sovereignty</id><content type="html" xml:base="http://localhost:4000/local-ai/2025/08/01/qwen3-30b-a3b-the-new-choice-for-nz-organizations-prioritizing-data-sovereignty.html"><![CDATA[<h2 id="the-recommendation-shift">The recommendation shift</h2>

<p>I’ve been asked by a number of New Zealand startups about the best local AI
model. For the past few months, I’ve recommended Llama 3.3 70B with 8-bit
quantization. I always ended my response with the caveat that it’s really a toy
model.</p>

<p>But With the arrival of <a href="https://qwenlm.github.io/blog/qwen3-30b-a3b/">Qwen3-30B-A3B-Instruct-2507</a>,
I think we finally have a local model that is good enough for both local exploration
and production use. Two things set this model apart from Llama 3.3 70B:</p>

<p><strong>Higher output quality</strong>. Based on my own benchmarks, Qwen3-30B’s performance
in Coding is slightly lower than ChatGPT-4o, but noticeably
higher than Claude’s haiku-3.5-20241022, a workhorse model that has been the
go-to for all my personal projects.</p>

<p><strong>Faster inference speed</strong>. Qwen3-30B-A3B runs at 78 tokens/second on M4 Max
with 128GB RAM (with MLX optimisation turned on). Previously, the biggest
problem I had with Llama-3.3-4-bit is its inference speed is only 7-10
tokens/second. It’s just a bit too slow for interactive use, particularly that
I’ve been trained to expect 52-68 tokens/second speed (as offered by claude’s
API). But 78? That’s more than usable.</p>

<p>Read on for a deep dive on 7 reasons why you should consider Qwen3-30B-A3B for
your local AI needs.</p>

<h2 id="1-benchmark-result-matching-larger-models">1. Benchmark result matching larger models</h2>

<p>Despite having just 30B parameters, Qwen3-30B-A3B competes with models 4-30 times its size:</p>

<table>
  <thead>
    <tr>
      <th>Benchmark</th>
      <th>Qwen3-30B-A3B</th>
      <th>GPT-4o</th>
      <th>Claude 3.5 Sonnet</th>
      <th>Gemini 1.5 Pro</th>
      <th>Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>ArenaHard</strong></td>
      <td><strong>91.0</strong></td>
      <td>85.3</td>
      <td>87.1</td>
      <td>-</td>
      <td>Complex reasoning &amp; instruction following</td>
    </tr>
    <tr>
      <td><strong>AIME’24/25</strong></td>
      <td><strong>80.4</strong></td>
      <td>41.4</td>
      <td>-</td>
      <td>52.7</td>
      <td>Advanced mathematical problem-solving</td>
    </tr>
    <tr>
      <td><strong>GPQA</strong></td>
      <td><strong>70.4%</strong></td>
      <td>65.1%</td>
      <td>72.3% (Opus)</td>
      <td>-</td>
      <td>Graduate-level science questions</td>
    </tr>
    <tr>
      <td><strong>LiveBench</strong></td>
      <td><strong>69.0</strong></td>
      <td>68.2 (GPT-4)</td>
      <td>-</td>
      <td>65.8 (Flash)</td>
      <td>Real-world task performance</td>
    </tr>
    <tr>
      <td><strong>Creative Writing</strong></td>
      <td><strong>86.0</strong></td>
      <td>84.2</td>
      <td>83.7 (Haiku)</td>
      <td>-</td>
      <td>Writing quality assessment</td>
    </tr>
  </tbody>
</table>

<p>For real-world applications, <a href="https://simonwillison.net/2025/Jul/29/qwen3-30b-a3b-instruct-2507/">Simon Willison</a> confirms these results in practical applications, noting performance “approaching GPT-4o and larger Qwen models.”</p>

<h2 id="2-the-speed-advantage-through-moe-architecture">2. The speed advantage through MoE architecture</h2>

<p>Qwen3-30B-A3B uses the Mixture of Experts (MoE) architecture. Think of
Qwen3-30B-A3B as having 128 specialist consultants on staff, but only calling
on the 8 most relevant experts for each task.</p>

<p>This Mixture of Experts architecture means the full 30.5B parameters are
available when needed, but the model runs at the speed of a much smaller 3.3B
parameter system.</p>

<h2 id="3-almost-one-click-local-deployment">3. (Almost) one-click local deployment</h2>

<p>The <a href="https://huggingface.co/lmstudio-community/Qwen3-30B-A3B-Instruct-2507-MLX-8bit">MLX 8-bit
model</a>
is readily available, optimized specifically for Apple Silicon deployment.
Simon Willison’s <a href="https://simonwillison.net/2025/Jul/29/qwen3-30b-a3b-instruct-2507/">deployment
guide</a>
provides additional implementation details.</p>

<h2 id="4-production-deployment-made-affordable">4. Production deployment made affordable</h2>

<p>For GPU deployment, the best value is a [Mac Mini M4 Pro with 64GB
RAM]https://www.apple.com/nz/shop/buy-mac/mac-mini/apple-m4-pro-chip-with-12-core-cpu-16-core-gpu-24gb-memory-512gb). It gives 79 tokens/second with MLX optimization for $4,299 NZD.</p>

<p>Or, you can go with one or two <a href="https://www.pbtech.co.nz/product/VGAASU350901/ASUS-ROG-ASTRAL-NVIDIA-GeForce-RTX-5090-OC-GAMING">RTX 5090 (NZD $6,799 each on
PBTech)</a>
runs about 48 tokens/seconds.</p>

<h2 id="5-extended-context-window">5. Extended context window</h2>

<p>Qwen3-30B-A3B brings a 256K token context window to local deployment.</p>

<p>This compares favorably to alternatives: Llama 3.3 70B supports 128K tokens,
while Claude Haiku 3.5 offers 200K. The extra headroom matters when you’re
building applications that need to maintain context across extended
interactions or process substantial documentation in single passes.</p>

<h2 id="6-tool-use">6. Tool use</h2>

<p>Qwen3-30B-A3B brings excellent function calling capabilities to local
deployment—a feature notably absent in Llama 3.3 70B. Qwen3-30B-A3B simplifies
this with the <a href="https://github.com/QwenLM/Qwen-Agent">Qwen-Agent framework</a>,
providing built-in support for:</p>

<ul>
  <li><strong>MCP (Model Context Protocol)</strong> configuration for standardized tool definitions</li>
  <li><strong>Native tool integration</strong> including code interpreters and API calls</li>
  <li><strong>Hybrid thinking modes</strong> that switch between deep reasoning and fast response</li>
</ul>

<h2 id="7-apache-20-licensing">7. Apache 2.0 licensing</h2>

<p>Qwen3-30B-A3B adopts the Apache 2.0 license, which is also a game-changer for
New Zealand startups. The Apache 2.0 license is one of the most permissive and
widely accepted open-source licenses, allowing you to use, modify, and
distribute the model with minimal restrictions. It’s the same license powering
many open source projects so your legal team probably already knows it.</p>

<p>This contrasts sharply with Llama’s custom license, which imposes user count
thresholds and revenue restrictions that can complicate commercial use.</p>

<h2 id="but-isnt-qwen3-from-china">But isn’t Qwen3 from China?</h2>

<p>Yes. But the beauty of local deployment lies in its complete neutrality.
Whether a model comes from Silicon Valley, Beijing, or Paris becomes irrelevant
when it runs exclusively on your hardware. Qwen3-30B-A3B offers the same data
sovereignty guarantees as any locally-deployed software: your data stays on
your servers, processed by your infrastructure, governed by your policies.</p>

<h2 id="your-evaluation-framework--model-choice">Your evaluation framework &gt; Model choice</h2>

<p>Before you get too excited about Qwen3-30B-A3B, let’s talk about the real
secret to success in AI: your evaluation framework.</p>

<p>The AI landscape changes weekly. New models, new capabilities, new price
points. Without a robust evaluation framework, you’re flying blind—making
decisions based on vendor marketing rather than measured performance. Build
your framework to answer three questions: Does this model solve our users’
actual problems? Can we measure improvement objectively? How do we capture
feedback to improve continuously? These capabilities matter more than which
model you choose today, because they determine how well you’ll adapt to
whatever comes next.</p>

<p>Think of AI models as engines and your evaluation framework as the vehicle
design. Anyone can buy the same engine, but how you integrate it, optimize it,
and apply it to specific use cases determines competitive advantage. Your
evaluation framework captures institutional knowledge that no model vendor can
replicate: understanding of your customers’ edge cases, industry-specific
quality standards, and the subtle differences between acceptable and
exceptional outputs in your domain.</p>

<p>While models depreciate rapidly—today’s state-of-the-art becomes tomorrow’s
baseline—your evaluation framework appreciates with use. Each test case
refined, each edge case captured, each performance metric validated adds to an
irreplaceable asset.</p>]]></content><author><name></name></author><category term="local-ai" /><summary type="html"><![CDATA[The recommendation shift]]></summary></entry><entry><title type="html">Two Insights from Tao’s Blue/Red Teams Metaphor: Software Testing’s Future and AI as a Coach</title><link href="http://localhost:4000/2025/07/29/a-broader-view-on-blue-red-team.html" rel="alternate" type="text/html" title="Two Insights from Tao’s Blue/Red Teams Metaphor: Software Testing’s Future and AI as a Coach" /><published>2025-07-29T09:17:00+12:00</published><updated>2025-07-29T09:17:00+12:00</updated><id>http://localhost:4000/2025/07/29/a-broader-view-on-blue-red-team</id><content type="html" xml:base="http://localhost:4000/2025/07/29/a-broader-view-on-blue-red-team.html"><![CDATA[Terence Tao's [blue and red
teams](https://mathstodon.xyz/@tao/114915604830689046) post crystalised several
insights about software testing and a different class of AI product that I have
been building but hadn't found the language to articulate until now.


He begins by describing the role of blue and red teams. Blue teams are
builders who construct and defend orders from chaos, while red teams are
hunters and invaders who find the weakest link in a coherent whole and exploit
it.

> In the field of cybersecurity, a distinction is made between the "blue team"
> task of building a secure system, and the "red team" task of locating
> vulnerabilities in such systems.  The blue team is more obviously necessary
> to create the desired product; but the red team is just as essential, given
> the damage that can result from deploying insecure systems.
>
> The nature of these teams mirror each other; mathematicians would call them
> "dual".  The output of a blue team is only as strong as its weakest link: a
> security system that consists of a strong component and a weak component
> (e.g., a house with a securely locked door, but an open window) will be
> insecure (and in fact worse, because the strong component may convey a false
> sense of security).  

His observation about the human dynamics of red teams is particularly insightful:

> Dually, the contributions to a red team can often be
> additive: a red team report that contains both a serious vulnerability and a
> more trivial one is more useful than a report that only contains the serious
> issue, as it is valuable to have the blue team address both vulnerabilities.

Two unexpected insights about QA and testers emerged: 

1) Red teams compound faster. Once there's a vulnerability, subsequent exploit
attempts can build upon it.  This can be quite different from blue teams, where
each new feature or component is a fresh start with a clear boundary from other
neighboring components.

2) Unconventional thinkers are better suited for red team roles. 

Today, in most software organizations, testers are treated as second-class
citizens and are not given the same respect as developers. Research shows
testers typically earn 25-33% less than software engineers with comparable
experience. In worse yet common cases, testers are brought in as an
afterthought to clean up after development is largely complete. 

As AI's code generation capabilities advance, testers may become far more
critical than they are today. Finding inconsistencies and ambiguities in
software would provide high-leverage positive impact on the system's integrity,
creating far more business value than just finding isolated bugs that
developers might overlook.

This also requires a shift in recruiting and hiring testers. Instead of manual
laborers content with repetitive tasks, we need people with explorative and
inquisitive mindsets. 

Tao then applies this framework to AI products—an insightful perspective
coming from a mathematician rather than a software engineer:

> Many of the proposed use cases for AI tools try to place such tools in the
> "blue team" category, such as creating code, text, images, or mathematical
> arguments in some semi-automated or automated fashion, that is intended for
> use for some external application.  However, in view of the unreliability and
> opacity of such tools, it may be better to put them to work on the "red
> team", critiquing the output of blue team human experts but not directly
> replacing that output; "blue team" AI use should only be permitted up to the
> capability of one's "red team" to catch and correct any errors generated.
> This approach not only plays to current AI strengths, such as breadth of
> exposure and fast feedback, but also mitigates the risks of deploying
> unverified AI output in high-stakes settings.
> 
> In my own personal experiments with AI, for instance, I have found it to be
> useful for providing additional feedback on some proposed text, argument,
> code, or slides that I have generated (including this current text).  I might
> only agree with a fraction of the suggestions generated by the AI tool; but I
> find that there are still several useful comments made that I do agree with,
> and incorporate into my own output.  This is a significantly less glamorous
> or intuitive use case for AI than the more commonly promoted "blue team" one
> of directly automating one's own output, but one that I find adds much more
> reliable value.

This suggests a new category of AI products focused on coaching and feedback
rather than direct output generation. 

[alexdong/high-taste](https://github.com/alexdong/high-taste) is my small
experiment in this direction—using AI to develop coding judgment rather than
generate code. Now imagine red team AI across every domain: tools that
critique your arguments, challenge your assumptions, stress-test your
strategies. Not to replace expertise, but to forge it.

AI's capabilities remain frustratingly jagged—brilliant at some tasks, 
unreliable at others. But perhaps that's exactly why red team AI works: 
it sidesteps AI's weaknesses while amplifying what it does well. Maybe the 
companies building critique tools today might discover a more constructive
path through the AI landscape than those chasing perfect generation.]]></content><author><name></name></author><summary type="html"><![CDATA[Terence Tao’s blue and red teams post crystalised several insights about software testing and a different class of AI product that I have been building but hadn’t found the language to articulate until now.]]></summary></entry><entry><title type="html">This is to have succeeded.</title><link href="http://localhost:4000/life/2022/10/31/Emerson-quote-this-is-to-have-succeeded.html" rel="alternate" type="text/html" title="This is to have succeeded." /><published>2022-10-31T14:38:00+13:00</published><updated>2022-10-31T14:38:00+13:00</updated><id>http://localhost:4000/life/2022/10/31/Emerson-quote-this-is-to-have-succeeded</id><content type="html" xml:base="http://localhost:4000/life/2022/10/31/Emerson-quote-this-is-to-have-succeeded.html"><![CDATA[Today, I printed out a quote from Emerson and put onto our fridge 
so we can all look at it everyday.

> To laugh often and much; to win the respect of intelligent people and
> the affection of children; to earn the appreciation of honest critics
> and endure the betrayal of false friends; to appreciate beauty; to
> find the best in others; to leave the world a bit better, whether by a
> healthy child, a garden patch, or a redeemed social condition; to know
> even one life has breathed easier because you have lived. This is to
> have succeeded."]]></content><author><name></name></author><category term="life" /><summary type="html"><![CDATA[Today, I printed out a quote from Emerson and put onto our fridge so we can all look at it everyday.]]></summary></entry></feed>