<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Resist the tempatation to anthropomorphizing LLM | Alex Dong’s Blog</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Resist the tempatation to anthropomorphizing LLM" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Chollet writes a great piece on why we even need prompt engineering and what’s the right mental model to have when we write prompts." />
<meta property="og:description" content="Chollet writes a great piece on why we even need prompt engineering and what’s the right mental model to have when we write prompts." />
<link rel="canonical" href="https://alexdong.com/resist-the-tempatation-to-anthropomorphizing-llm.html" />
<meta property="og:url" content="https://alexdong.com/resist-the-tempatation-to-anthropomorphizing-llm.html" />
<meta property="og:site_name" content="Alex Dong’s Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-09-21T20:33:00+12:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Resist the tempatation to anthropomorphizing LLM" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-09-21T20:33:00+12:00","datePublished":"2025-09-21T20:33:00+12:00","description":"Chollet writes a great piece on why we even need prompt engineering and what’s the right mental model to have when we write prompts.","headline":"Resist the tempatation to anthropomorphizing LLM","mainEntityOfPage":{"@type":"WebPage","@id":"https://alexdong.com/resist-the-tempatation-to-anthropomorphizing-llm.html"},"url":"https://alexdong.com/resist-the-tempatation-to-anthropomorphizing-llm.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="preconnect" href="https://cdn.jsdelivr.net">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fontsource/iosevka@5.0.8/index.min.css">
  <link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://alexdong.com/feed.xml" title="Alex Dong&apos;s Blog" /></head><body><header class="site-header" role="banner">
  <div class="wrapper">
    <div style="text-align: center;">
      <a class="site-title" rel="author" href="/">Stream of Thoughts from Alex Dong</a>
      <p style="margin: 0; font-size: 0.875rem; color: var(--meta-color);">What I find interesting, intriguing or insightful</p>
    </div>
  </div>
</header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Resist the tempatation to anthropomorphizing LLM</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2025-09-21T20:33:00+12:00" itemprop="datePublished">Sep 21, 2025
      </time><span class="post-categories"><span class="post-category p-category">prompt-engineering</span><span aria-hidden="true"> | </span><span class="post-category p-category">quotes</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><a href="https://fchollet.substack.com/p/how-i-think-about-llm-prompt-engineering">Chollet</a> 
writes a great piece on why we even need prompt engineering and what’s the right 
mental model to have when we write prompts.</p>

<p>Instead of thinking of LLMs as intelligent agents that understand our intent,
we should think of them as massive databases of programs, and our prompts are
just keys to look up those programs.  (Emphasis mine.)</p>

<blockquote>
  <p>There are thousands of variations you could have used, each resulting in a
similar-yet-slightly-different program. And that’s why prompt engineering is
needed. There is no a-priori reason why your first, naive program key would
result in the optimal program for the task. The LLM is not going to
“understand” what you meant and then perform it in the best possible way —
it’s merely going to fetch the program that your prompt points to, among many
possible locations you could have landed on.</p>

  <p><strong>Prompt engineering is the process of searching through program space to find
the program that empirically seems to perform best on your target task.</strong> It’s
no different than trying different keywords when doing a Google search for a
piece of software.</p>

  <p>If LLMs actually understood what you told them, there would be no need for
this search process, since the amount of information conveyed about your
target task does not change whether your prompt uses the word “rewrite”
instead “rephrase”, or whether you prefix your prompt with “think steps by
steps”. Never assume that the LLM “gets it” the first time — keep in mind
that your prompt is but an address in an infinite ocean of programs, all
captured as a by-product of organizing tokens into a vector space via an
autoregressive optimization objective.</p>

  <p>As always, the most important principle for understanding LLMs is that you
should resist the temptation of anthropomorphizing them.</p>
</blockquote>

  </div><a class="u-url" href="/resist-the-tempatation-to-anthropomorphizing-llm.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer">
  <div class="wrapper">
    <div style="text-align: center;">
      <a class="u-email" href="mailto:me@alexdong.com">me@alexdong.com</a>
    </div>
  </div>
</footer></body>

</html>
