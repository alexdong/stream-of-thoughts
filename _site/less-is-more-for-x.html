<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Less is More for X | Alex Dong’s Blog</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Less is More for X" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Joe turned me onto a series of papers by Pengfei Liu that challenge the conventional wisdom that “more data is always better” for post-training LLMs." />
<meta property="og:description" content="Joe turned me onto a series of papers by Pengfei Liu that challenge the conventional wisdom that “more data is always better” for post-training LLMs." />
<link rel="canonical" href="http://localhost:4000/less-is-more-for-x.html" />
<meta property="og:url" content="http://localhost:4000/less-is-more-for-x.html" />
<meta property="og:site_name" content="Alex Dong’s Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-09-26T22:58:00+12:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Less is More for X" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-09-26T22:58:00+12:00","datePublished":"2025-09-26T22:58:00+12:00","description":"Joe turned me onto a series of papers by Pengfei Liu that challenge the conventional wisdom that “more data is always better” for post-training LLMs.","headline":"Less is More for X","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/less-is-more-for-x.html"},"url":"http://localhost:4000/less-is-more-for-x.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="preconnect" href="https://cdn.jsdelivr.net">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fontsource/iosevka@5.0.8/index.min.css">
  <link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Alex Dong&apos;s Blog" /></head><body><header class="site-header" role="banner">
  <div class="wrapper">
    <div style="text-align: center;">
      <a class="site-title" rel="author" href="/">Stream of Thoughts from Alex Dong</a>
      <p style="margin: 0; font-size: 0.875rem; color: var(--meta-color);">What I find interesting, intriguing or insightful</p>
    </div>
  </div>
</header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Less is More for X</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2025-09-26T22:58:00+12:00" itemprop="datePublished">Sep 26, 2025
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><a href="https://x.com/joecole">Joe</a> turned me onto a series of papers by <a href="https://scholar.google.com/citations?hl=en&amp;user=oIz_CYEAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Pengfei
Liu</a>
that challenge the conventional wisdom that “more data is always better” for
post-training LLMs.</p>

<p>Collectively, these papers show that for
<a href="https://arxiv.org/pdf/2502.11886">RL</a>,
<a href="https://arxiv.org/pdf/2502.03387">Reasoning</a> and
<a href="https://arxiv.org/pdf/2509.17567">Agentic</a> tasks, a smaller yet higher-quality
training dataset can outperform similar-scale ones, like OpenAI-o1-preview. For
example, in the case of Reasoning, using only 1% of the training data yields
a 45.8% absolute improvement on math and programming tasks. I thought it was
worth sharing a few details from the reasoning paper.</p>

<p>On the hypothesis:</p>

<blockquote>
  <p>We hypothesize that successful reasoning emerges from the synergy of rich
pre-trained knowledge and sufficient computational resources at inference
time. These developments suggest that if models possess rich reasoning
knowledge and adequate computational space, activating their reasoning
capabilities may require only a small number of high-quality samples that
encourage extended deliberation, rather than massive fine-tuning datasets. We
propose the Less-Is-More Reasoning (LIMO) Hypothesis, identifying two
critical factors determining the elicitation threshold for complex reasoning:
(1) the latent presence of prerequisite knowledge within the model’s
parameters, and (2) the effectiveness of minimal exemplars in demonstrating
problem-solving processes that encourage extended deliberation. The sample
efficiency of eliciting advanced reasoning is thus bounded by the model’s
encoded knowledge foundation and its exposure to training samples that
effectively utilize inference-time computation space.</p>
</blockquote>

<p>When they describe how they constructed the smaller, higher-quality dataset,
they emphasize that the “higher quality” label refers to the most difficult
problems. Rather than gradually increasing difficulty as in
<a href="https://en.wikipedia.org/wiki/Curriculum_learning">Curriculum Learning</a>, they
focus on that challenging tail.</p>

<blockquote>
  <p>We implemented a systematic multi-stage filtration pipeline … we first
applied a baseline difficulty filter using a short-CoT mathematical model.
Problems that this model solved correctly within four attempts were excluded,
ensuring that only non-trivial problems remained. Next, we sampled 32
solution attempts and used the empirical success rate as a difficulty
indicator. Problems that were successfully solved in only 1–3 out of 32
attempts were retained.</p>
</blockquote>

<p>After refining the dataset this way, they constructed the training trace with
larger reasoning models and a set of heuristics:</p>

<blockquote>
  <p>Elaborated Reasoning: Comprehensive exploration of logical steps without
premature conclusions</p>

  <p>Self-Verification: Regular validation of intermediate results and logical
consistency</p>

  <p>Exploratory Approach: Consideration of multiple possibilities before reaching
conclusions</p>

  <p>Adaptive Granularity: Appropriate detail level across simple and complex
deductions</p>

  <p>To quantify these qualities, we implemented a rule-based scoring system that
calculated weighted metrics for each dimension. Elaborated Reasoning was
measured by solution length (30% weight); Self-Verification through frequency
of validation-related words like “check” and “verify” (20% weight);
Exploratory Approach by counting tentative expressions such as “perhaps” and
“might” (25% weight); and Adaptive Granularity via connective phrases like
“therefore” and “since” (25% weight). All keyword frequencies were normalized
by text length to ensure fair comparison across solutions of different sizes.</p>
</blockquote>

<p>Taken together, the results are quite impressive. Still, the more I think about
it, the more I feel that this process of curating a smaller, higher-quality
dataset is essentially a manual distillation process that transfers the
capability from larger reasoning models to smaller ones. Because none of the
papers include an ablation study, it’s unclear to me how much of the improvement
is due to the curated dataset vs. the fact that the larger models are used to
generate the training trace.</p>

  </div><footer class="post-footer">
      <nav class="post-categories" aria-label="Categories"><a class="post-category p-category" rel="tag" href="/categories/ai-training/">ai-training</a></nav>
    </footer><a class="u-url" href="/less-is-more-for-x.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer">
  <div class="wrapper">
    <div style="text-align: center;">
      <a class="u-email" href="mailto:me@alexdong.com">me@alexdong.com</a>
    </div>
  </div>
</footer></body>

</html>
