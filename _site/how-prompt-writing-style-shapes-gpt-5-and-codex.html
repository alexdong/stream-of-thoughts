<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>How Prompt Writing Style Shapes GPT-5 and Codex | Alex Dong’s Blog</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="How Prompt Writing Style Shapes GPT-5 and Codex" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Of many things that impresses me about OpenAI GPT-5-Codex, one was how responsive and “light” it feels to use. Compared to the pages of outputs from Claude Code, GPT-5-Codex feels more efficient, more to the point and much more steerable. Some of these would come from the gpt-5-codex model itself, but I suspect a lot of it comes from the prompt engineering that OpenAI has done." />
<meta property="og:description" content="Of many things that impresses me about OpenAI GPT-5-Codex, one was how responsive and “light” it feels to use. Compared to the pages of outputs from Claude Code, GPT-5-Codex feels more efficient, more to the point and much more steerable. Some of these would come from the gpt-5-codex model itself, but I suspect a lot of it comes from the prompt engineering that OpenAI has done." />
<link rel="canonical" href="http://localhost:4000/how-prompt-writing-style-shapes-gpt-5-and-codex.html" />
<meta property="og:url" content="http://localhost:4000/how-prompt-writing-style-shapes-gpt-5-and-codex.html" />
<meta property="og:site_name" content="Alex Dong’s Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-09-25T21:06:00+12:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="How Prompt Writing Style Shapes GPT-5 and Codex" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-09-25T21:06:00+12:00","datePublished":"2025-09-25T21:06:00+12:00","description":"Of many things that impresses me about OpenAI GPT-5-Codex, one was how responsive and “light” it feels to use. Compared to the pages of outputs from Claude Code, GPT-5-Codex feels more efficient, more to the point and much more steerable. Some of these would come from the gpt-5-codex model itself, but I suspect a lot of it comes from the prompt engineering that OpenAI has done.","headline":"How Prompt Writing Style Shapes GPT-5 and Codex","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/how-prompt-writing-style-shapes-gpt-5-and-codex.html"},"url":"http://localhost:4000/how-prompt-writing-style-shapes-gpt-5-and-codex.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="preconnect" href="https://cdn.jsdelivr.net">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fontsource/iosevka@5.0.8/index.min.css">
  <link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Alex Dong&apos;s Blog" /></head><body><header class="site-header" role="banner">
  <div class="wrapper">
    <div style="text-align: center;">
      <a class="site-title" rel="author" href="/">Stream of Thoughts from Alex Dong</a>
      <p style="margin: 0; font-size: 0.875rem; color: var(--meta-color);">What I find interesting, intriguing or insightful</p>
    </div>
  </div>
</header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">How Prompt Writing Style Shapes GPT-5 and Codex</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2025-09-25T21:06:00+12:00" itemprop="datePublished">Sep 25, 2025
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>Of many things that impresses me about OpenAI GPT-5-Codex, one was how
responsive and “light” it feels to use. Compared to the pages of
outputs from <a href="/due-to-odd-jax-issues.html">Claude Code</a>, GPT-5-Codex feels more
efficient, more to the point and much more steerable. Some of these would come
from the <code class="language-plaintext highlighter-rouge">gpt-5-codex</code> model itself, but I suspect a lot of it comes from the
prompt engineering that OpenAI has done.</p>

<p>Tonight, I compared the <a href="https://github.com/openai/codex/blob/rust-v0.36.0/codex-rs/core/gpt_5_codex_prompt.md">system prompt for
codex</a>
against the <a href="https://www.reddit.com/r/PromptEngineering/comments/1mknun8/i_have_extracted_the_gpt5_system_prompt/">leaked system prompt for
GPT-5</a> and I noticed the following differences:</p>

<ol>
  <li>
    <p>The codex sentences are much <strong>denser</strong>. The GPT-5 language is warm,
supportive, lightly humorous, encouraging curiorsity. Explicitly focuses on
emotional presence and teaching style. The GPT-5-Codex prompt is
neutral, concise, factural, collaborative. It intentionally strips
personality to maintain clarity and consistency.</p>

    <p>I ran a “clause density” analysis on both prompts. The codex prompt has
4.8 average clauses per sentence, whereas the GPT-5 prompt has 2.1. Which 
is why the codex prompts are so much more packed, routinely carrying 5-8
clauses via semicolons and commas.</p>
  </li>
  <li>
    <p>The codex seems to have a much <strong>less constrained dialogue flow</strong>. The
prompt focuses entirely on the structure of the answers, not interaction
dynamics. The GPT-5 prompt is more restrictive. It limits the number of
clarifying questions to one at the start of the conversation. It also
encourages taking initiative when the next step is obvious.</p>

    <p>I also noticed that the codex prompt has lower imperative ratio
(commands/sentences) and yet higher negation frequency (don’ts), an analysis
that baffled me.</p>
  </li>
  <li>
    <p>The codex content guidance emphasises <strong>brevity</strong> and <strong>scanability</strong>. It
encourages the use of headers, bullets, and grouping related points. The
GPT-5 prompt is more focused on <strong>tone</strong> and <strong>engagement</strong> with
instructions like “Supportive thoroughness”, “Lighthearted interactions”,
“Adaptive teaching”, and “Confidence-building”.</p>
  </li>
  <li>
    <p>The codex adapts based on <strong>task</strong> type (code explanations, simple tasks,
big changes, casual one-offs) whereas the GPT-5 prompt adjusts based on <strong>user</strong>
proficiency and emotional needs.</p>
  </li>
  <li>
    <p>Based on the Readability analysis, the codex is written for university
graduates (Flesch-Kincaid Grade Level 14) whereas the GPT-5 prompt is
written for high school (Flesch-Kincaid Grade Level 10).</p>
  </li>
</ol>

<p>Here is a summary of the quantitative differences between the two prompts:</p>

<table>
  <thead>
    <tr>
      <th>Metric</th>
      <th>GPT-5-Codex (Prompt B)</th>
      <th>GPT-5 (Prompt A)</th>
      <th>Interpretation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Lexical Density</strong></td>
      <td>0.82</td>
      <td>0.78</td>
      <td>Codex is more content-word heavy</td>
    </tr>
    <tr>
      <td><strong>Type–Token Ratio (TTR)</strong></td>
      <td>0.77</td>
      <td>0.68</td>
      <td>Codex uses more varied vocabulary</td>
    </tr>
    <tr>
      <td><strong>Flesch Reading Ease</strong></td>
      <td>29.0</td>
      <td>42.1</td>
      <td>Codex is harder to read (graduate level)</td>
    </tr>
    <tr>
      <td><strong>Flesch–Kincaid Grade</strong></td>
      <td>14.1</td>
      <td>10.4</td>
      <td>Codex ≈ college sophomore; GPT-5 ≈ high school</td>
    </tr>
    <tr>
      <td><strong>Gunning Fog Index</strong></td>
      <td>16.6</td>
      <td>13.9</td>
      <td>Codex significantly denser, more technical</td>
    </tr>
    <tr>
      <td><strong>SMOG Index</strong></td>
      <td>15.0</td>
      <td>12.6</td>
      <td>Codex ~Grade 15 vs. GPT-5 ~Grade 12</td>
    </tr>
    <tr>
      <td><strong>Punctuation Load</strong></td>
      <td>3.2</td>
      <td>0.9</td>
      <td>Codex has ~3.5× more commas/semicolons</td>
    </tr>
    <tr>
      <td><strong>Imperative Ratio</strong></td>
      <td>0.10</td>
      <td>0.25</td>
      <td>GPT-5 gives more direct instructions</td>
    </tr>
    <tr>
      <td><strong>Negation Frequency</strong></td>
      <td>6</td>
      <td>3</td>
      <td>Codex has more “don’ts” and negatives</td>
    </tr>
  </tbody>
</table>

<p>One higher-level take-away from studying these prompts is that just how
steerable a model is depends a lot on the prompt engineering.</p>

<hr />

<p>GPT-5-Codex System Prompt</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>### Final answer structure and style guidelines

- Plain text; CLI handles styling. Use structure only when it helps scanability.
- Headers: optional; short Title Case (1-3 words) wrapped in **…**; no blank line before the first bullet; add only if they truly help.
- Bullets: use - ; merge related points; keep to one line when possible; 4–6 per list ordered by importance; keep phrasing consistent.
- Monospace: backticks for commands/paths/env vars/code ids and inline examples; use for literal keyword bullets; never combine with **.
- Code samples or multi-line snippets should be wrapped in fenced code blocks; add a language hint whenever obvious.
- Structure: group related bullets; order sections general → specific → supporting; for subsections, start with a bolded keyword bullet, then items; match complexity to the task.
- Tone: collaborative, concise, factual; present tense, active voice; self‑contained; no "above/below"; parallel wording.
- Don'ts: no nested bullets/hierarchies; no ANSI codes; don't cram unrelated keywords; keep keyword lists short—wrap/reformat if long; avoid naming formatting styles in answers.
- Adaptation: code explanations → precise, structured with code refs; simple tasks → lead with outcome; big changes → logical walkthrough + rationale + next actions; casual one-offs → plain sentences, no headers/bullets.
</code></pre></div></div>

<hr />

<p>GPT-5 System Prompt</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Do not reproduce song lyrics or any other copyrighted material, even if asked.

You are an insightful, encouraging assistant who combines meticulous clarity with genuine enthusiasm and gentle humor.

Supportive thoroughness: Patiently explain complex topics clearly and comprehensively.

Lighthearted interactions: Maintain friendly tone with subtle humor and warmth.

Adaptive teaching: Flexibly adjust explanations based on perceived user proficiency.

Confidence-building: Foster intellectual curiosity and self-assurance.

Do **not** say the following: would you like me to; want me to do that; do you want me to; if you want, I can; let me know if you would like me to; should I; shall I.

Ask at most one necessary clarifying question at the start, not the end.

If the next step is obvious, do it. Example of bad: I can write playful examples. would you like me to? Example of good: Here are three playful examples:..
</code></pre></div></div>

  </div><footer class="post-footer">
      <nav class="post-categories" aria-label="Categories"><a class="post-category p-category" rel="tag" href="/categories/open-ai/">open-ai</a><span aria-hidden="true"> | </span><a class="post-category p-category" rel="tag" href="/categories/prompt-engineering/">prompt-engineering</a></nav>
    </footer><a class="u-url" href="/how-prompt-writing-style-shapes-gpt-5-and-codex.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer">
  <div class="wrapper">
    <div style="text-align: center;">
      <a class="u-email" href="mailto:me@alexdong.com">me@alexdong.com</a>
    </div>
  </div>
</footer></body>

</html>
